import { addKeyword, EVENTS } from "@builderbot/bot";
import fs from "fs/promises";
import Replicate from "replicate";
import { generateTimer } from "../utils/generateTimer";
import { getHistoryParse, handleHistory } from "../utils/handleHistory";
import { getFullCurrentDate } from "src/utils/currentDate";
import { pdfQuery } from "src/services/pdf";
import axios from 'axios';
import { G4F } from "g4f";


const PROMPT_SELLER = `Como experto en ventas con aproximadamente 15 a√±os de experiencia en embudos de ventas y generaci√≥n de leads, tu tarea es mantener una conversaci√≥n agradable, responder a las preguntas del cliente sobre nuestros productos y, finalmente, guiarlos para reservar una cita. Tus respuestas deben basarse √∫nicamente en el contexto proporcionado:

### D√çA ACTUAL
{CURRENT_DAY}

### HISTORIAL DE CONVERSACI√ìN (Cliente/Vendedor)
{HISTORY}

### BASE DE DATOS
{DATABASE}

Para proporcionar respuestas m√°s √∫tiles, puedes utilizar la informaci√≥n proporcionada en la base de datos. El contexto es la √∫nica informaci√≥n que tienes. Ignora cualquier cosa que no est√© relacionada con el contexto.

### EJEMPLOS DE RESPUESTAS IDEALES:

- buenas bienvenido a..
- un gusto saludarte en..
- por supuesto tenemos eso y ...

### INTRUCCIONES
- Mant√©n un tono profesional y siempre responde en primera persona.
- NO ofrescas promociones que no existe en la BASE DE DATOS
- NO respondas con saludo
- Respuestas cortas ideales para enviar por whatsapp con emojis.

Respuesta √∫til adecuadas para enviar por WhatsApp (en espa√±ol):`;

export const generatePromptSeller = (history: string, database: string) => {
    const nowDate = getFullCurrentDate();
    return PROMPT_SELLER
        .replace('{HISTORY}', history)
        .replace('{CURRENT_DAY}', nowDate)
        .replace('{DATABASE}', database);
};

const g4f = new G4F();

// Inicializa la instancia de Replicate utilizando la variable de entorno
const replicate = new Replicate({
    auth: process.env.REPLICATE_API_TOKEN, // Aseg√∫rate de tener la variable de entorno configurada
});

// Funci√≥n para transcribir el archivo usando la API de Whisper en Replicate
const transcribeAudio = async (audioBuffer): Promise<any> => {
    try {
        
        const base64Audio = audioBuffer.toString('base64'); // Convierte el archivo a base64

        // Configura el input para la API de Whisper
        const input = {
            audio: `data:audio/wav;base64,${base64Audio}`
        };

        // Llama a la API de Replicate para transcribir el audio
        const output = await replicate.run(
            "openai/whisper:4d50797290df275329f202e48c76360b3f22b08d28c196cbc54600319435f8d2", 
            { input }
        );

        console.log(`ü§ñ Full Transcription Result: ${JSON.stringify(output, null, 2)}`);
        return output; // Devuelve el resultado de la transcripci√≥n
    } catch (error) {
        console.error("Error transcribing audio:", error);
        return null;
    }
};

const flowVoiceNote = addKeyword(EVENTS.VOICE_NOTE)
    .addAnswer("dame un momento para escucharte...üôâ")
    .addAction(async (ctx, { provider, state, flowDynamic }) => {
        try {
            // Guarda el archivo localmente
            const localPath = await provider.saveFile(ctx, { path: "./tmp" });
            if (!localPath) {
                console.log("Error: La ruta del archivo es inv√°lida o no se pudo guardar el archivo.");
                return;
            }
            console.log(`üìù Fin voz a texto....[TEXT]: ${localPath}`);

            // Lee el archivo en memoria
            const audioBuffer = await fs.readFile(localPath);
            
            // Elimina el archivo despu√©s de leerlo
            await fs.unlink(localPath);
            
            // Transcribe el audio y obt√©n el texto
            const transcriptionResult = await transcribeAudio(audioBuffer,);

            if (transcriptionResult) {
                console.log(`ü§ñ Full Transcription Result: ${JSON.stringify(transcriptionResult, null, 2)}`);
                // Extrae y muestra el texto transcrito
                const transcribedText = transcriptionResult.transcription;
                console.log(`ü§ñ Transcribed Text: ${transcribedText}`);

                try {
                    const history = getHistoryParse(state);
                    const dataBase = await pdfQuery(transcribedText);
                    console.log({ dataBase });
                    const promptInfo = generatePromptSeller(history, dataBase);

                    // Crear los mensajes para la API de chat
                    const messages = [
                        { role: "system", content: "Eres un asistente personal" },
                        { role: "assistant", content: promptInfo },
                    ];

                    const options = {
                        model: "gpt-4",
                        debug: true,
                    };

                    // Obtener la respuesta del bot
                    const response = await g4f.chatCompletion(messages, options);
                    await handleHistory({ content: response, role: 'assistant' }, state);
                    const chunks = dataBase.split(/(?<!\d)\.\s+/g);
                    console.log(`${new Date()}\nPregunta: ${transcribedText} \nRespuesta: ${dataBase}`);
                    for (const chunk of chunks) {
                        await flowDynamic([{ body: chunk.trim(), delay: generateTimer(150, 250) }]);
                    }
                } catch (err) {
                    console.log(`[ERROR]:`, err);
                    return;
                }
            } else {
                console.log("ü§ñ No se pudo transcribir el audio.");
                // Si no se puede transcribir el audio, maneja el error apropiadamente
            }
        } catch (err) {
            console.log(`[ERROR]:`, err);
        }
    });

export { flowVoiceNote };